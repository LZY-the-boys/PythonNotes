假设 n=gpu=8, c=ctx=2048 token, batch=16; 
单次forward 理论极限走 $8*2048*16=262144$ token
数据长度如 multipack_sampler/testdata.json， 共 $9521300$ token

用一般的forward实现，需要走 $6144/(16*8) = 48$ step, 
效率比是 $9521300 / 48*262144  = 0.7566849391$

用sampler packing实现，需要 $37$ step,
效率比是 $9521300 / 37*262144  = 0.9816453264$


- 挑战1：gpu之间不能共享，是n个c,不是连续的n*c 
- 挑战2：数据的长度x_i不固定，且不能截断，是N个x_i塞到gpu中, 不是连续的N*x_i
=> [装箱算法]

```
每次分配任务 [start_index:start_index + l] 到一个batch中，同时累积处理数据长度为s
start_index start_index+l s
0 159 260553
159 326 521271
326 485 783056
485 651 1044821
651 819 1305587
819 985 1565699
985 1157 1827138
1157 1329 2088223
1329 1491 2349941
1491 1660 2611085
1660 1827 2872566
1827 1997 3134498
1997 2158 3395296
2158 2324 3657288
2324 2492 3919327
2492 2667 4180607
2667 2833 4441070
2833 3003 4702361
3003 3177 4964104
3177 3347 5225690
3347 3515 5487294
3515 3688 5747518
3688 3853 6008366
3853 4023 6268441
4023 4197 6528798
4197 4364 6790417
4364 4545 7051343
4545 4720 7311767
4720 4876 7573453
4876 5040 7834595
5040 5203 8096230
5203 5368 8356484
5368 5548 8617328
5548 5720 8879023
5720 5894 9140640
5894 6069 9402390
6069 6144 9521300
```